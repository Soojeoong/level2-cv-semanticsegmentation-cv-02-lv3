{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/conda_envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/ephemeral/conda_envs/torch/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# python native\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "# external library\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import albumentations as A\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로를 입력하세요\n",
    "\n",
    "IMAGE_ROOT = \"IMAGE_PATH\"\n",
    "LABEL_ROOT = \"LABEL_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "\n",
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "\n",
    "pngs = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n",
    "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".png\"\n",
    "}\n",
    "\n",
    "jsons = {\n",
    "    os.path.relpath(os.path.join(root, fname), start=LABEL_ROOT)\n",
    "    for root, _dirs, files in os.walk(LABEL_ROOT)\n",
    "    for fname in files\n",
    "    if os.path.splitext(fname)[1].lower() == \".json\"\n",
    "}\n",
    "pngs = sorted(pngs)\n",
    "jsons = sorted(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# GroupKFold split 저장 함수\n",
    "def save_kfold_splits(filenames, labelnames, groups, n_splits=5, output_dir='splits'):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(gkf.split(filenames, [0] * len(filenames), groups)):\n",
    "        train_filenames = filenames[train_idx].tolist()\n",
    "        valid_filenames = filenames[valid_idx].tolist()\n",
    "        train_labelnames = labelnames[train_idx].tolist()\n",
    "        valid_labelnames = labelnames[valid_idx].tolist()\n",
    "        \n",
    "        split_data = {\n",
    "            'train_filenames': train_filenames,\n",
    "            'train_labelnames': train_labelnames,\n",
    "            'valid_filenames': valid_filenames,\n",
    "            'valid_labelnames': valid_labelnames\n",
    "        }\n",
    "        \n",
    "        # JSON 파일로 저장\n",
    "        with open(f'{output_dir}/fold_{fold_idx}.json', 'w') as f:\n",
    "            json.dump(split_data, f)\n",
    "\n",
    "# 데이터 초기화 및 GroupKFold split 저장\n",
    "filenames = np.array(pngs)\n",
    "labelnames = np.array(jsons)\n",
    "groups = [os.path.dirname(fname) for fname in filenames]\n",
    "\n",
    "save_kfold_splits(filenames, labelnames, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 has no overlapping files between train and valid sets:\n",
      "Fold 1 has no overlapping files between train and valid sets:\n",
      "Fold 2 has no overlapping files between train and valid sets:\n",
      "Fold 3 has no overlapping files between train and valid sets:\n",
      "Fold 4 has no overlapping files between train and valid sets:\n",
      "No overlapping files found among all validation sets.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 폴더와 fold 수 설정\n",
    "output_dir = 'splits'\n",
    "n_splits = 5\n",
    "\n",
    "# 각 fold의 train과 validation 파일 리스트를 담을 집합 초기화\n",
    "all_valid_files = set()\n",
    "\n",
    "# 각 fold 내의 train과 validation 간 교집합 확인 및 모든 validation 파일 수집\n",
    "for fold_idx in range(n_splits):\n",
    "    split_file = os.path.join(output_dir, f'fold_{fold_idx}.json')\n",
    "    \n",
    "    with open(split_file, 'r') as f:\n",
    "        split_data = json.load(f)\n",
    "    \n",
    "    train_files = set(split_data['train_filenames'])\n",
    "    valid_files = set(split_data['valid_filenames'])\n",
    "    \n",
    "    # 각 fold 내의 교집합 확인\n",
    "    intersection = train_files & valid_files\n",
    "    if intersection:\n",
    "        print(f\"Fold {fold_idx} has overlapping files between train and valid sets:\", intersection)\n",
    "    else:\n",
    "        print(f\"Fold {fold_idx} has no overlapping files between train and valid sets:\")\n",
    "    \n",
    "    # 모든 fold의 validation 파일 수집\n",
    "    all_valid_files.update(valid_files)\n",
    "\n",
    "# 모든 fold의 validation 파일 간 중복 확인\n",
    "valid_intersection = set()\n",
    "valid_files_list = list(all_valid_files)\n",
    "\n",
    "for i in range(len(valid_files_list)):\n",
    "    for j in range(i + 1, len(valid_files_list)):\n",
    "        if valid_files_list[i] == valid_files_list[j]:\n",
    "            valid_intersection.add(valid_files_list[i])\n",
    "\n",
    "if valid_intersection:\n",
    "    print(\"Overlapping files found among all validation sets:\", valid_intersection)\n",
    "else:\n",
    "    print(\"No overlapping files found among all validation sets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
